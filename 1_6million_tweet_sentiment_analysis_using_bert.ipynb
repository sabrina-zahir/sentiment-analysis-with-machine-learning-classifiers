{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "a0mh-TPx3XJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin-1', header = None)\n",
        "df.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
        "df = df.drop(columns=['id', 'Date', 'Query', 'User'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KWrxYsrx3XJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pQHy3SdJ3XJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.Sentiment)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IXrDqxPM3XJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df.Sentiment.replace(4,1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "l8cBOjgo3XJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df.Sentiment)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ud8sVGHv3XJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\n",
        "mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\n",
        "urls = re.compile(r\"https?://\\S+\")\n",
        "\n",
        "def process_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = hashtags.sub(' hashtag', text)\n",
        "    text = mentions.sub(' entity', text)\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "trusted": true,
        "id": "6Vw1sBhl3XJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tweet'] = df.Tweet.apply(process_text)"
      ],
      "metadata": {
        "trusted": true,
        "id": "2YSKH4Qm3XKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "51u2kNKn3XKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = df.Sentiment.values\n",
        "text = df.Tweet.values"
      ],
      "metadata": {
        "trusted": true,
        "id": "kgzodZz23XKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification,AdamW"
      ],
      "metadata": {
        "trusted": true,
        "id": "3al4gtRm3XKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZYy0yAy03XKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_mask = []\n",
        "for i in text:\n",
        "    encoded_data = tokenizer.encode_plus(\n",
        "    i,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64,\n",
        "    pad_to_max_length = True,\n",
        "    return_attention_mask= True,\n",
        "    return_tensors='pt')\n",
        "    input_ids.append(encoded_data['input_ids'])\n",
        "    attention_mask.append(encoded_data['attention_mask'])\n",
        "input_ids = torch.cat(input_ids,dim=0)\n",
        "attention_mask = torch.cat(attention_mask,dim=0)\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dSD5RVhh3XKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,SequentialSampler,RandomSampler,TensorDataset,random_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "R2QBjxPf3XKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(input_ids,attention_mask,labels)\n",
        "train_size = int(0.8*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset,val_dataset = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "print('Training Size - ',train_size)\n",
        "print('Validation Size - ',val_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "cy95O52Z3XKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),\n",
        "                     batch_size = 32)\n",
        "val_dl = DataLoader(val_dataset,sampler = SequentialSampler(val_dataset),\n",
        "                     batch_size = 32)"
      ],
      "metadata": {
        "trusted": true,
        "id": "E3CS5u083XKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dl),len(val_dl)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qNM827Fm3XKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "'bert-base-uncased',\n",
        "num_labels = 2,\n",
        "output_attentions = False,\n",
        "output_hidden_states = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tk0HbCwV3XKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nGpKxXl93XKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "v1vryuze3XKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps=1e-8)"
      ],
      "metadata": {
        "trusted": true,
        "id": "usfBPQqR3XKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 1\n",
        "total_steps = len(train_dl)*epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,\n",
        "                                           num_training_steps=total_steps)"
      ],
      "metadata": {
        "trusted": true,
        "id": "su8bzw3r3XKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds,labels):\n",
        "    pred_flat = np.argmax(preds,axis=1).flatten()\n",
        "    label_flat = labels.flatten()\n",
        "    return np.sum(pred_flat==label_flat)/len(label_flat)"
      ],
      "metadata": {
        "trusted": true,
        "id": "I3Bhu7Dr3XKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader_test):\n",
        "    model.eval()\n",
        "    loss_val_total = 0\n",
        "    predictions,true_vals = [],[]\n",
        "    for batch in dataloader_test:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {\n",
        "            'input_ids':batch[0],\n",
        "            'attention_mask': batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "    loss_val_avg = loss_val_total / len(dataloader_test)\n",
        "    predictions = np.concatenate(predictions,axis=0)\n",
        "    true_vals = np.concatenate(true_vals,axis=0)\n",
        "    return loss_val_avg,predictions,true_vals"
      ],
      "metadata": {
        "trusted": true,
        "id": "2D3mFxZ-3XKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(train_dl, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(train_dl)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(val_dl)\n",
        "    val_acc = accuracy(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'Accuracy: {val_acc}')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "OcA70RZY3XKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = './'\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_zzC-wES3XKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "output_dir = './'\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "metadata": {
        "trusted": true,
        "id": "1vwI6N_x3XKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Sentiment(sent):\n",
        "    output_dir = './'\n",
        "    tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 64,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    input_id = encoded_dict['input_ids']\n",
        "\n",
        "    attention_mask = encoded_dict['attention_mask']\n",
        "    input_id = torch.LongTensor(input_id)\n",
        "    attention_mask = torch.LongTensor(attention_mask)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_loaded = model_loaded.to(device)\n",
        "    input_id = input_id.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    index = logits.argmax()\n",
        "    return index"
      ],
      "metadata": {
        "trusted": true,
        "id": "FosSqLw73XKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = Sentiment('i am nervous')"
      ],
      "metadata": {
        "trusted": true,
        "id": "yS4-w4wf3XKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ans == 1:\n",
        "    print(\"Positive\")\n",
        "else:\n",
        "    print(\"Negative\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "KTIjanSD3XKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "1pXSOnSx3XKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'models/bert-custom'\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bg3okTjG3XKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'models_loaded/distilbert-custom'\n",
        "model_loaded.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ecfrfav43XKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39AJvWcy3XKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}